# 故障排除
如果您在使用 IPFS 时遇到问题，请使用此页面调试您的问题并快速找到解决方案。
## 检查您的 IPFS 守护进程是否正在运行
`ipfs get <cid>` 如果您在尝试运行诸如 return 之类的常见命令时遇到意外行为 `Error: merkledag: not found`，则问题很可能是您的守护程序未运行。这可以通过运行 `ipfs daemon` 和使用不同的终端与守护进程交互来补救。
## IPFS 运行缓慢
诸如此类的命令 `ipfs ls` 将进入网络以尝试查找数据。如果由于某种原因无法找到该数据，那么 Kubo 将永远寻找拥有该数据的人。无法找到数据的常见原因是：

- 网上没有人有。
- 有一个节点有数据，但它在 NAT 后面。
- 拥有它的节点尚未以您的节点可以找到它的方式发布数据。

您可以查看 Bitswap 的使用情况，`ipfs bitswap stat` 以帮助您确定是否在寻找数据时遇到困难。如果您要查找的数据永久存在，`wantlist` 那么您的节点可能遇到了上面列出的常见原因之一。

一些函数也有类似 `--stream` 或 `--progress` 的标志，可以帮助您查看增量更新。对于日志记录行为，有 `ipfs log`，`ipfs log level`可以帮助您进一步检查子系统。

如果您担心当数据在网络上不可用时您的 CLI 响应不够快，您可以将超时标志传递给基本上所有的 Kubo 命令。
## 文件传输
首先，确保 IPFS 在两台机器上运行。要验证，请 `ipfs id` 在每台机器上运行并检查该 `Addresses` 字段中是否有任何内容。如果它显示`null`，那么您的节点不在线，您需要运行 `ipfs daemon`。

现在，让我们调用要传输文件的节点节点“A”和要将文件传输到节点“B”的节点。在 `node a` 上，使用命令 `ipfs add` 将文件添加到 IPFS 。这将打印出您添加的内容的多重哈希。现在，在 `node b` 上，您可以使用 `ipfs get <hash>` 获取内容。

	# On A
	ipfs add myfile.txt
	> added QmZJ1xT1T9KYkHhgRhbv8D7mYrbemaXwYUkg7CeHdrk1Ye myfile.txt
	
	# On B
	ipfs get QmZJ1xT1T9KYkHhgRhbv8D7mYrbemaXwYUkg7CeHdrk1Ye
	> Saving file(s) to QmZJ1xT1T9KYkHhgRhbv8D7mYrbemaXwYUkg7CeHdrk1Ye
	> 13 B / 13 B [=====================================================] 100.00% 1s
如果成功并且您的节点下载了文件，那么恭喜！您刚刚使用 IPFS 在互联网上移动文件！但是，如果该 `ipfs get` 命令挂起，没有输出，请继续阅读。

## 检查现有连接
要做的第一件事是仔细检查两个节点实际上都在运行和在线。为此，请 `ipfs id` 在每台机器上运行。如果两个节点都显示一些地址（如下例所示），那么您的节点在线。

	{
	    "ID": "QmTNwsFkLAed15kQEC1ZJWPfoNbBQnMFojfJKQ9sZj1dk8",
	        "PublicKey": "CAASpgIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDZb6znj3LQZKP1+X81exf+vbnqNCMtHjZ5RKTCm7Fytnfe+AI1fhs9YbZdkgFkM1HLxmIOLQj2bMXPIGxUM+EnewN8tWurx4B3+lR/LWNwNYcCFL+jF2ltc6SE6BC8kMLEZd4zidOLPZ8lIRpd0x3qmsjhGefuRwrKeKlR4tQ3C76ziOms47uLdiVVkl5LyJ5+mn4rXOjNKt/oy2O4m1St7X7/yNt8qQgYsPfe/hCOywxCEIHEkqmil+vn7bu4RpAtsUzCcBDoLUIWuU3i6qfytD05hP8Clo+at+l//ctjMxylf3IQ5qyP+yfvazk+WHcsB0tWueEmiU5P2nfUUIR3AgMBAAE=",
	        "Addresses": [
	            "/ip4/127.0.0.1/tcp/4001/p2p/QmTNwsFkLAed15kQEC1ZJWPfoNbBQnMFojfJKQ9sZj1dk8",
	        "/ip4/127.0.0.1/udp/4001/quic/p2p/QmTNwsFkLAed15kQEC1ZJWPfoNbBQnMFojfJKQ9sZj1dk8",
	        "/ip4/192.168.2.131/tcp/4001/p2p/QmTNwsFkLAed15kQEC1ZJWPfoNbBQnMFojfJKQ9sZj1dk8",
	        "/ip4/192.168.2.131/udp/4001/quic/p2p/QmTNwsFkLAed15kQEC1ZJWPfoNbBQnMFojfJKQ9sZj1dk8"
	        ],
	       "AgentVersion": "kubo/0.4.11-dev/",
	        "ProtocolVersion": "ipfs/0.1.0"
	}
接下来，检查节点之间是否有连接。您可以通过 `ipfs swarm peers` 在一个节点上运行并在输出中检查另一个节点的对等 ID 来执行此操作。

- 如果两个节点已连接，但 `ipfs get` 命令仍然挂起，则说明发生了意想不到的事情，我建议提交一个问题。
- 如果它们没有连接，那么让我们尝试调试原因。（注意：如果你只是想让事情正常进行，你可以跳到手动连接node a\node b。但是，通过调试过程并在 IRC 上向 IPFS 团队报告发生的事情有助于我们了解人们遇到的常见陷阱）。

### 检查供应商
在 IPFS 上请求内容时，节点会在 DHT 中搜索“提供者记录”以查看谁拥有什么内容。让我们手动执行此操作 `node b` 以确保 `node b` 能够确定 `node a` 具有数据。运行 `ipfs dht findprovs <hash>`。我们希望看到 `node a` 打印出的对等 ID。如果此命令没有返回任何内容（或返回不是 `node a` 的 ID ），则网络上不存在具有该数据的 A 的记录。`node a` 如果在没有运行守护进程的情况下添加数据，就会发生这种情况。如果发生这种情况，您可以继续 `ipfs dht provide <hash>` 向 `node a` 网络宣布您拥有该哈希。然后，如果您重新启动 `ipfs get` 命令，`node b` 现在应该可以分辨出 `node a` 它想要的内容。如果 `node a` 的对等 ID 出现在初始 `findprovs`调用或手动提供哈希没有解决问题，那么很可能无法 `node b` 连接到 `node a` .
### 检查地址
在这种情况下，尽管知道它需要，但根本无法与  `node b`  建立连接，可能的罪魁祸首是错误的 NAT。当 `node b` 获悉它需要连接到时`node a`，它会检查`node a` DHT 的地址，然后开始尝试连接到它们。 我们可以通过运行 `ipfs dht findpeer <node a peerID>` 来检查这些地址 `node b` 。此命令应返回 `node a` 的地址列表。如果它没有返回任何地址，那么您应该尝试运行前面步骤中的手动提供命令。地址的示例输出可能如下所示：

	/ip4/127.0.0.1/tcp/4001
	/ip4/127.0.0.1/udp/4001/quic
	/ip4/192.168.2.133/tcp/4001
	/ip4/192.168.2.133/udp/4001/quic
	/ip4/88.157.217.196/tcp/63674
	/ip4/88.157.217.196/udp/63674/quic
在这种情况下，我们可以看到一个本地主机 (127.0.0.1) 地址、一个 LAN 地址（192.168..一个）和另一个地址。如果这第三个地址与您的外部 IP 相匹配，那么网络就知道您节点的有效外部地址。此时，可以安全地假设您的节点存在难以穿越 NAT 的情况。如果是这种情况，您可以尝试在 `node a` 的路由器上启用 UPnP 或 NAT-PMP，然后重试该过程。否则，您可以尝试手动连接 `node a` 到 `node b`.
### 手动连接node a到node b
在 `node b` 运行时获取包含其公共 IP 地址的多地址 `ipfs id` 之一，然后在运行时。您也可以尝试使用 `node aipfs swarm connect <multiaddr>` 中继连接。如果这仍然不起作用，那么您应该加入 IRC 并在那里寻求帮助或在 GitHub 上提交问题。

如果这个手动步骤确实有效，那么您可能遇到了 NAT 穿越问题，并且 IPFS 无法弄清楚如何让它通过。请向我们报告此类情况，以便我们努力解决问题。
## 去调试
当你看到 ipfs 做某事时（使用大量 CPU、内存或其他奇怪的事情），你要做的第一件事就是收集所有相关的分析信息。

有一个命令 (`ipfs diag profile`) 可以为您执行此操作并将结果打包到一个 zip 文件中，随时可以附加到错误报告中。

如果你觉得勇敢，你可以转储这些信息并自己调查：

1. 协程转储：

		curl localhost:5001/debug/pprof/goroutine\?debug=2 > ipfs.stacks`
2. 30 秒 CPU 配置文件：

		curl localhost:5001/debug/pprof/profile > ipfs.cpuprof`
3. 堆跟踪转储：

		curl localhost:5001/debug/pprof/heap > ipfs.heap
4. 内存统计。在 JSON 中查看 `memstats`对象：

		curl localhost:5001/debug/vars > ipfs.vars
5. 系统信息：

		ipfs diag sys > ipfs.sysinfo`

### 分析堆栈转储
首先要寻找的是挂起的 goroutines ——任何被卡住超过一分钟的 goroutine 都会在跟踪中注意到这一点。它看起来像：

	goroutine 2306090 [semacquire, 458 minutes]:
	sync.runtime_Semacquire(0xc8222fd3e4)
	    /home/whyrusleeping/go/src/runtime/sema.go:47 +0x26
	sync.(*Mutex).Lock(0xc8222fd3e0)
	    /home/whyrusleeping/go/src/sync/mutex.go:83 +0x1c4
	gx/ipfs/QmedFDs1WHcv3bcknfo64dw4mT1112yptW1H65Y2Wc7KTV/yamux.(*Session).Close(0xc8222fd340, 0x0, 0x0)
	    /home/whyrusleeping/gopkg/src/gx/ipfs/QmedFDs1WHcv3bcknfo64dw4mT1112yptW1H65Y2Wc7KTV/yamux/session.go:205 +0x55
	gx/ipfs/QmWSJzRkCMJFHYUQZxKwPX8WA7XipaPtfiwMPARP51ymfn/go-stream-muxer/yamux.(*conn).Close(0xc8222fd340, 0x0, 0x0)
	    /home/whyrusleeping/gopkg/src/gx/ipfs/QmWSJzRkCMJFHYUQZxKwPX8WA7XipaPtfiwMPARP51ymfn/go-stream-muxer/yamux/yamux.go:39 +0x2d
	gx/ipfs/QmZK81vcgMhpb2t7GNbozk7qzt6Rj4zFqitpvsWT9mduW8/go-peerstream.(*Conn).Close(0xc8257a2000, 0x0, 0x0)
	    /home/whyrusleeping/gopkg/src/gx/ipfs/QmZK81vcgMhpb2t7GNbozk7qzt6Rj4zFqitpvsWT9mduW8/go-peerstream/conn.go:156 +0x1f2
	    created by gx/ipfs/QmZK81vcgMhpb2t7GNbozk7qzt6Rj4zFqitpvsWT9mduW8/go-peerstream.(*Conn).GoClose
	    /home/whyrusleeping/gopkg/src/gx/ipfs/QmZK81vcgMhpb2t7GNbozk7qzt6Rj4zFqitpvsWT9mduW8/go-peerstream/conn.go:131 +0xab
在顶部，您可以看到这个 goroutine（编号 2306090）已等待获取信号量 458 分钟。那似乎很糟糕。查看跟踪的其余部分，我们看到它正在等待的确切行是 `runtime/sema.go` 的第 47 行。这不是特别有用，所以我们继续。接下来，我们看到调用是在 `yamux/session.go` 的第205行的 Close 方法中进行的 `yamux.Session`。这似乎是问题所在。

根据该信息，在堆栈转储的其余部分中寻找可能持有相关信号量的另一个 `goroutine`。

goroutines 挂起有几个不同的原因：

- `semacquire` 意味着我们正在等待获取锁或信号量。
- `select` 意味着 goroutine 挂在 select 语句中，并且没有任何情况产生任何结果。
- `chan receive` 并 `chan send` 分别等待接收或发送的频道。
- `IO wait` 通常意味着我们正在等待一个套接字来读取或写入数据，尽管这可能意味着我们正在等待一个非常慢的文件系统。

如果你看到这些标签中的任何一个没有后缀, `X minutes`，这通常意味着没有问题——你只是在短暂的等待中发现了那个 goroutine。如果等待时间超过几分钟，这要么意味着 goroutine 没有做太多事情，要么就是出了什么问题。

如果你看到很多 goroutines，考虑使用 [stackparse](https://github.com/whyrusleeping/stackparse) （打开新窗口）对它们进行筛选、排序和汇总。

### 分析 CPU 配置文件
go 团队写了一篇关于[分析 go 程序的优秀文章](http://blog.golang.org/profiling-go-programs) （打开新窗口）. 如果您已经收集了以上信息，您可以跳到他们开始谈论的地方 `go tool pprof`。我分析这些的首选方法是运行命令web，它生成一个 SVG 点图并在浏览器中打开它。这是轻松指出代码中的热点位置的最快方法。
### 分析变量和内存统计信息
- [ReadMemStats](https://golang.org/pkg/runtime/#ReadMemStats)  输出为 JSON 格式，包括獾存储统计信息、命令行运行和 Go运行时的输出 。 （打开新窗口）. 
- [MemStats_](https://golang.org/pkg/runtime/#MemStats) （打开新窗口）有关于内存分配和垃圾收集的有用信息。

