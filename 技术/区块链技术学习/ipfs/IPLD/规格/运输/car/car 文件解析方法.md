

当前 Car 的技术层面的东西已经该知道的都知道了，现在的要解决的问题如下

需要解决的问题：

- 需要解决大文件/复杂目录和文件(统称存储对象)的高效、稳定、可靠的传输

当前解决方案：

1. UI 端将该存储对象打成 car 文件
2. 分片传输到后端
3. 后端根据前端的分片方案，将分片导入 IPFS，导入的存储对象包含所有数据和dag存储路由
4. 导入方案可验证整个文件的完整性
5. 返回给前端 root cid

遇到问题：分片方案与分片还原方案和整个数据完整性问题

分片方案现在有两种
	
- 方案A
	- 方法 
		- 使用前端将 car 文件按照文件进行拆分(无视数据内容)
	- 优点  
		- 该方案对于前后端都比较好实现，实现难度小
		- 对于数据完整性可以有保证，因为最终可以使用 car 文件的 hash 作为完整验证方案，保证数据最终一致性
	- 问题
		1. 该方案在数据整体架构上有数据放大效应，最少将数据在服务端系统上存储多次，对处理大文件极为不利
		2. 因为该方案需要将 car 文件完整的汇聚到1个节点 可能导致接收集群 ipfs 节点因为磁盘雪崩导致服务异常
		3. 需要强制两段处理模式，处理时间成倍
- 方案 B
	- 方法
		- 前端将 car 文件按照模式进行解析，按照 car 文件中的数据 block 和dag block 传输给后端
	- 优点
		- 完美解决服务器中转存储单个 car 文件巨大问题
		- 服务器将不会有大转存，每个 block 非常小，不会占用额外的存储空间
		- 服务器端资源将完美的全部利用，这样减少服务器单点压力
		- 全部基于 car 库实现，前端实现简单，后端不用额外开发实现
	- 缺点
		- 因为传输文件大小或者目录复杂度不可控，所以，以原始的 256kb 分片的方案会导致对服务器请求数量指数上涨，变相 DDOS
		- 无法验证数据可靠性
- 新方案C
	- 方法
		- 前端根据 car 文件的拼装方法(如图)，通过 LEB128 解析数据 varint ，然后按照段处理每个部分的字节长度来进行块拆分和数据发送。
		- 后端接收到数据块，同样按照 LEB128 将解析数据 varint 进行还原
		- 没还原1个 block 记录或者去除总表中的 block ，最终全部上传完成，即可完整整个文件上传

				|--------- Header --------| |---------------------------------- Data -----------------------------------|
				
				[ varint | DAG-CBOR block ] [ varint | CID | block ] [ varint | CID | block ] [ varint | CID | block ] …
	- 好处
		- 完美解决服务器存储压力和网络传输问题
	- 缺点
		- 数据完整性方案需要进一步确认
		- 前后端需要对 car 文件核心有一定的了解  	

## 参考资料
[car 参考资料](https://github.com/pangzheng/BOOKS/blob/master/%E6%8A%80%E6%9C%AF/%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/ipfs/IPLD/%E8%A7%84%E6%A0%BC/%E8%BF%90%E8%BE%93/car/%E5%86%85%E5%AE%B9%E5%8F%AF%E5%AF%BB%E5%9D%80%E6%A1%A3%E6%A1%88%20(CAR%20:%20.car)%20v1.md)		
			

		      
		  