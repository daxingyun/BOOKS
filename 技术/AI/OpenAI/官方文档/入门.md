# 入门
## 介绍
### 概述
OpenAI API 几乎可以应用于任何涉及理解或生成自然语言或代码的任务。我们提供一系列具有不同功率级别的[模型](https://beta.openai.com/docs/models)，适用于不同的任务，并且能够[微调](https://beta.openai.com/docs/guides/fine-tuning)您自己的自定义模型。这些模型可用于从内容生成到语义搜索和分类的所有领域。
### 关键概念
我们建议您完成我们的快速入门教程，以通过实际操作的交互式示例熟悉关键概念。

[快速入门教程](https://beta.openai.com/docs/quickstart)

通过构建快速示例应用程序进行学习

### `提示 Prompts` and `completions`
- [completions](https://beta.openai.com/docs/api-reference/completions) 端点位于我们 API 的中心。

	它为我们的模型提供了一个简单的界面，非常灵活和强大。您输入一些文本作为提示，模型将生成一个文本补全，尝试匹配您提供的任何上下文或模式。
	
		例如，如果您给 API 提示“为冰淇淋店写一个标语(Write a tagline for an ice cream shop)” ，它会返回一个完成，例如“我们为每一勺都带来微笑！(We serve up smiles with every scoop!)”

	[设计提示](https://beta.openai.com/docs/guides/completion/prompt-design)本质上是您“编程”模型的方式，通常是通过提供一些说明或一些示例。这不同于为单一任务设计的大多数其他 NLP 服务，例如情感分类或命名实体识别。相反，completions 端点几乎可以用于任何任务，包括内容或代码生成、摘要、扩展、对话、创意写作、风格转换等。

### 分词 Token 
我们的模型通过将文本分解为标记来理解和处理文本。标记可以是单词或只是字符块。

	例如，单词 “hamburger” 被分解为标记 “ham”、“bur” 和 “ger”，而像 “pear” 这样的短而常见的单词是一个标记。
许多标记以空格开头

	例如“hello”和“bye”。

在给定的 API 请求中处理的分词数量取决于输入和输出的长度。根据粗略的经验法则，

	对于英文文本，1 个标记大约为 4 个字符或 0.75 个单词。
要记住的一个限制是，您的文本提示和生成的完成组合不能超过模型的最大上下文长度（对于大多数模型，这是 2048 个标记或大约 1500 个单词）。查看我们的[分词器工具](https://beta.openai.com/tokenizer)，了解有关文本如何转换为分词的更多信息。
### 模型
API 由一组具有不同功能和价位的模型提供支持。我们的基础 GPT-3 模型称为 Davinci、Curie、Babbage 和 Ada。我们的 Codex 系列是 GPT-3 的后代，已接受自然语言和代码方面的培训。要了解更多信息，请访问我们的[模型文档](https://beta.openai.com/docs/models)。

## 快速开始
OpenAI 训练了非常擅长理解和生成文本的尖端语言模型。我们的 API 提供对这些模型的访问，可用于解决几乎任何涉及处理语言的任务。

在本快速入门教程中，您将构建一个简单的示例应用程序。在此过程中，您将学习使用 API 完成任何任务的关键概念和技术，包括：

- 内容生成
- 总结
- 分类、分类和情感分析
- 数据提取
- 翻译
- 还有很多！

### 介绍
[completions](https://beta.openai.com/docs/api-reference/completions) 端点是我们 API 的核心，它提供了一个极其灵活和强大的简单接口。您输入一些文本作为提示，API 将返回一个文本完成，尝试匹配您提供的任何指令或上下文。

- Prompt 

		为冰淇淋店写一个标语。
- Completion

		每一勺我们都会微笑！

您可以将其视为非常高级的自动完成——模型处理您的文本提示并尝试预测接下来最有可能出现的内容。

### 1 从指令开始
假设您想创建一个宠物名字生成器。从头开始想出名字很难！

首先，您需要一个明确说明您想要什么的提示。让我们从一个指令开始。提交此提示以生成您的第一个完成。

	Suggest one name for a horse.  # 用这个 prompt 生成结果
不错！现在，试着让你的指示更具体。

	Suggest one name for a black horse. # 用这个 prompt 生成结果
如您所见，在我们的提示中添加一个简单的形容词会改变生成的完成。设计提示本质上就是您“编程”模型的方式。
### 2 个添加一些示例
制定好的说明对于获得好的结果很重要，但有时它们还不够。让我们试着让你的指令更复杂。

	Suggest three names for a horse that is a superhero.  # 用这个 prompt 生成结果
这个完成并不是我们想要的。这些名称非常通用，而且模型似乎没有接受我们指令中的马匹部分。让我们看看能否让它提出一些更相关的建议。

在许多情况下，向模型展示和告诉模型您想要什么是很有帮助的。在您的提示中添加示例可以帮助传达模式或细微差别。尝试提交此提示，其中包含几个示例。

	Suggest three names for an animal that is a superhero.
	
	Animal: Cat
	Names: Captain Sharpclaw, Agent Fluffball, The Incredible Feline
	Animal: Dog
	Names: Ruff the Protector, Wonder Canine, Sir Barks-a-Lot
	Animal: Horse
	Names:
好的！添加我们期望给定输入的输出示例有助于模型提供我们正在寻找的名称类型。
### 3 个调整您的设置
提示设计并不是您可以使用的唯一工具。您还可以通过调整设置来控制完成。最重要的设置之一称为温度(Temperature)。

您可能已经注意到，如果您在上面的示例中多次提交相同的提示，模型将始终返回相同或非常相似的完成。这是因为您的温度设置为0。

尝试将 `temperature` 设置为 1 重新提交几次相同的提示。

![](./pic/openai-docs1.png)
看看发生了什么？当温度高于 0 时，每次提交相同的提示会导致不同的完成。

请记住，该模型预测哪个文本最有可能跟在它前面的文本之后。温度是一个介于 0 和 1 之间的值，基本上可以让您控制模型在进行这些预测时的置信度。降低温度意味着它将承担更少的风险，并且完成将更加准确和确定。升高温度将导致更多样化的完成。

- 深入了解

	了解标记和概率
	
	 我们的模型通过将文本分解为称为标记的更小单元来处理文本。标记可以是单词、单词块或单个字符。编辑下面的文本以查看它是如何被标记化的。

		I have an orange cat named Butterscotch.	
	- 人类解析
		
		我有一只名为 Butterscotch 的橙猫.
	- 算法解析

		我有一个橙猫命名的但叔叔婴儿床通道
		
	 像“猫”这样的常用词是单个标记，而不太常用的词通常被分解成多个标记。例如，“Butterscotch”翻译成四个标记：“But”、“ters”、“cot”和“ch”。许多标记以空格开头，例如“hello”和“bye”。

	给定一些文本，该模型确定下一个最有可能出现的标记。例如，文本 “Horses are my favorite” 最有可能跟随标记 “animal”。

		Horses are my favorite
	- animal 
		
		可能性 49.65%
	- animals 
	
		可能性 42.58%
	- \n

		可能性 3.49%
	- ！

		可能性 0.91%
	这是温度发挥作用的地方。如果您在温度设置为 0 的情况下提交此提示 4 次，则模型将始终在下一个返回“animal”，因为它的概率最高。如果你提高温度，它会承担更多的风险，并考虑概率较低的分词。

	- 如果温度为 0 运行4次
		- 马是我最喜欢的 `animal`
		- 马是我最喜欢的 `animal`
		- 马是我最喜欢的 `animal`
		- 马是我最喜欢的 `animal`
	- 如果温度为 1 运行4次
		- 马是我最喜欢的 `animal`
		- 马是我最喜欢的 `animals`
		- 马是我的最爱 `！`
		- 马是我最喜欢的 `animal`
	通常最好为所需输出明确定义的任务设置低温。较高的温度对于需要多样性或创造力的任务可能很有用或者如果您想为最终用户或人类专家生成一些变化以供选择。

	对于您的昵称生成器，您可能希望能够生成很多名字创意。0.6 的适中温度应该可以正常工作。

### 4 构建您的应用程序
#### Node.JS(还支持 python，当前只使用 nodejs )
现在您已经找到了一个好的提示和设置，您已经准备好构建您的爱称生成器了！我们编写了一些代码来帮助您入门 - 按照以下说明下载代码并运行应用程序。

- 第一步 设置

	如果您没有安装 Node.js，[请从此处安装](https://nodejs.org/en/)。然后通过克隆[此存储库](https://github.com/openai/openai-quickstart-node)下载代码。

		git clone https://github.com/openai/openai-quickstart-node.git
	如果您不想使用 git，您也可以使用此 [zip 文件](https://github.com/openai/openai-quickstart-node/archive/refs/heads/master.zip)下载代码。
- 第二步 添加您的 API 密钥

	导航到项目目录并复制示例环境变量文件。

		cd openai-quickstart-node
		cp .env.example .env
	复制您的秘密 API 密钥并将其设置为 `OPENAI_API_KEY` 您新创建的 `.env` 文件中的。如果您还没有创建密钥，页面创建。

	- 重要说明

		使用 Javascript 时，所有 API 调用都应仅在服务器端进行，因为在客户端浏览器代码中进行调用会暴露您的 API 密钥。[有关更多详细信息，请参见此处](https://beta.openai.com/docs/api-reference/authentication)。
- 第三步 运行应用

	在项目目录下运行以下命令安装依赖并运行应用程序。

		npm install
		npm run dev
	在浏览器中打开 `http://localhost:3000`，您应该会看到昵称生成器！

#### 理解代码
`generate.js` 在 `openai-quickstart-node/pages/api` 文件夹中打开。在底部，您将看到生成我们在上面使用的提示的函数。由于用户将输入他们宠物的动物类型，因此它会动态换出指定动物的提示部分。


	function generatePrompt(animal) {
	  const capitalizedAnimal = animal[0].toUpperCase() + animal.slice(1).toLowerCase();
	  return `Suggest three names for an animal that is a superhero.
	
	Animal: Cat
	Names: Captain Sharpclaw, Agent Fluffball, The Incredible Feline
	Animal: Dog
	Names: Ruff the Protector, Wonder Canine, Sir Barks-a-Lot
	Animal: ${capitalizedAnimal}
	Names:`;
	}
在 `generate.js` 中的第 9 行，您将看到发送实际 API 请求的代码。如上所述，它使用温度为 0.6的 [completions](https://beta.openai.com/docs/api-reference/completions)端点。

	const completion = await openai.createCompletion({
	  model: "text-davinci-003",
	  prompt: generatePrompt(req.body.animal),
	  temperature: 0.6,
	});
就是这样！您现在应该完全了解您的（超级英雄）宠物名称生成器如何使用 OpenAI API！

### 关闭
这些概念和技术将大大有助于您构建自己的应用程序。也就是说，这个简单的例子只是展示了可能性的一小部分！completions 端点非常灵活，几乎可以解决任何语言处理任务，包括内容生成、摘要、语义搜索、主题标记、情感分析等等。

要记住的一个限制是，对于大多数模型，单个 API 请求在提示和完成之间最多只能处理 2,048 个标记（大约 1,500 个单词）。

- 深入学习

	型号和定价
	
	我们提供一系列具有不同功能和[价位的型号](https://openai.com/api/pricing/)。在本教程中，我们使用了我们最强大的自然语言模型。我们建议在试验时使用 `text-davinci-003` 此模型，因为它会产生最佳结果。一旦一切正常，您就可以查看其他模型是否可以以更低的延迟和成本产生相同的结果。

	单个请求（提示和完成）中处理的分词总数不能超过模型的最大上下文长度。对于大多数模型，这是 2,048 个标记或大约 1,500 个单词。根据粗略的经验法则，对于英文文本，1 个标记大约为 4 个字符或 0.75 个单词。

	定价为每 1,000 个分词即用即付，前 3 个月可使用 18 美元的免费信用额度。[了解更多](https://openai.com/api/pricing/)。

对于更高级的任务，您可能会发现自己希望能够提供更多的示例或上下文，而不是单个提示中的内容。[微调](https://beta.openai.com/docs/guides/fine-tuning) API 是执行此类更高级任务的绝佳选择。微调允许您提供数百甚至数千个示例来为您的特定用例定制模型。

## 开发库
### Python 绑定
我们提供 Python 绑定，您可以按如下方式安装：

	$ pip install openai
安装后，您可以使用绑定和您的密钥运行以下命令：

	import os
	import openai

	# 从环境变量或秘密管理服务加载API密钥
	openai.api_key = os.getenv("OPENAI_API_KEY")
	
	response = openai.Completion.create(model="text-davinci-003", prompt="Say this is a test", temperature=0, max_tokens=7)
绑定还将安装一个命令行实用程序，您可以按如下方式使用：

	$ openai api completions.create -m text-davinci-003 -p "Say this is a test" -t 0 -M 7 --stream
### Node.js 库
我们还有一个 Node.js 库，您可以通过在 Node.js 项目目录中运行以下命令来安装它：

	$ npm install openai
安装后，您可以使用该库和您的密钥运行以下命令：

	const { Configuration, OpenAIApi } = require("openai");
	const configuration = new Configuration({
	  apiKey: process.env.OPENAI_API_KEY,
	});
	const openai = new OpenAIApi(configuration);
	const response = await openai.createCompletion({
	  model: "text-davinci-003",
	  prompt: "Say this is a test",
	  temperature: 0,
	  max_tokens: 7,
	});
### 社区图书馆
下面的库由更广泛的开发人员社区构建和维护。如果您想在此处添加新库，请参阅此[帮助文章](https://help.openai.com/en/articles/6684216-adding-your-api-client-to-the-community-libraries-page)。

请注意，OpenAI 不会验证这些项目的正确性或安全性

- C# / .NET
	- OpenAI-API-dotnet by OkGoDoIt
	- Betalgo.OpenAI.GPT3 by Betalgo
- Crystal
	- openai-crystal by sferik
- Dart
	- gpt_3_dart by boronhub
- Go
	- go-gpt3 by sashabaranov
- Java
	- openai-java by Theo Kanning
- Node.js
	- openai-api by Njerschow
	- openai-api-node by erlapso
	- gpt-x by ceifa
	- gpt3 by poteat
	- gpts by thencc
	- @dalenguyen/openai by dalenguyen
	- tectalic/openai by tectalic
- PHP
	- orhanerday/open-ai by orhanerday
	- tectalic/openai by tectalic
- Python
	- chronology by OthersideAI
- R
	- rgpt3 by ben-aaron188
- Ruby
	- openai by nileshtrivedi
	- uby-openai by alexrudall
- Unity
	- OpenAi-Api-Unity by hexthedev
- Unreal Engine
	- OpenAI-Api-Unreal by KellanM

## 模型
### 概述
OpenAI API 由一系列具有不同功能和价位的模型提供支持。您还可以通过[微调](https://beta.openai.com/docs/guides/fine-tuning)为您的特定用例自定义我们的基本模型。

模型|描述
---|---
[GPT-3](https://beta.openai.com/docs/models/gpt-3)|一组可以理解和生成自然语言的模型
[Codex](https://beta.openai.com/docs/models/codex)有限公测|一组可以理解和生成代码的模型，包括将自然语言翻译成代码
[Content filter](https://beta.openai.com/docs/models/content-filter)内容过滤器|可以检测文本是否敏感或不安全的微调模型

我们计划随着时间的推移不断改进我们的模型。为此，我们可能会使用您提供给我们的数据来提高其准确性、功能和安全性。[了解更多](https://help.openai.com/en/articles/5722486)。

访问我们的研究人员[模型索引](https://beta.openai.com/docs/model-index-for-researchers)，详细了解我们的研究论文中介绍了哪些模型以及 InstructGPT 和 GPT-3.5 等模型系列之间的差异。

### GPT-3
我们的 GPT-3 模型可以理解和生成自然语言。我们提供四种主要型号，它们具有不同的功率级别，适用于不同的任务。达芬奇是最有能力的模型，而阿达是最快的。

最新款|描述|最大请求|训练数据
---|---|---|---|
text-​​davinci-003|功能最强大的 GPT-3 模型。可以完成其他模型可以完成的任何任务，通常具有更高的质量、更长的输出和更好的指令遵循。还支持在文本中[插入补全](https://beta.openai.com/docs/guides/completion/inserting-text)。|4,000 Token|	截至 2021 年 6 月
text-curie-001|非常有能力，但比达芬奇更快，成本更低。|2,048 Token|截至 2019 年 10 月
text-babbage-001|能够执行简单的任务，速度非常快，成本更低。|2,048 Token|截至 2019 年 10 月
text-​​ada-001|能够执行非常简单的任务，通常是 GPT-3 系列中最快的型号，而且成本最低。|2,048 Tokem|截至 2019 年 10 月

虽然 Davinci 通常是最有能力的，但其他模型可以以显着的速度或[成本优势](https://openai.com/api/pricing)非常出色地执行某些任务。例如，curie 可以执行许多与 davinci 相同的任务，但速度更快，成本仅为达芬奇的 1/10。

我们建议在试验时使用 Davinci，因为它会产生最好的结果。一旦一切正常，我们鼓励您尝试其他模型，看看您是否能以更低的延迟获得相同的结果。您还可以通过在特定任务上[微调其他模型](https://beta.openai.com/docs/guides/fine-tuning)来提高它们的性能。
### 特定功能模型
主要的 GPT-3 模型旨在与文本[completion](https://beta.openai.com/docs/guides/completion)端点一起使用。我们还提供专门用于其他端点的模型。

我们的 GPT-3 模型的旧版本有 `davinci、curie、babbage`和` ada`。这些旨在与我们的[微调](https://beta.openai.com/docs/guides/fine-tuning)端点一起使用。[了解更多](https://help.openai.com/en/articles/5832130)。

我们用于[创建嵌入](https://beta.openai.com/docs/guides/embeddings)和[编辑文本](https://beta.openai.com/docs/guides/completion/editing-text)的端点使用它们自己的一组专用模型。

- davinci

	Davinci 是最有能力的模型系列，可以执行其他模型可以执行的任何任务，而且通常只需要很少的指令。对于需要对内容有大量理解的应用程序，例如针对特定受众的摘要和创意内容生成，Davinci 将产生最佳结果。这些增加的功能需要更多的计算资源，因此 Davinci 每次 API 调用的成本更高，并且不如其他模型快。

	Davinci 的另一个亮点是理解文本的意图。davinci 擅长解决多种逻辑问题和解释人物的动机。davinci 已经能够解决一些涉及因果关系的最具挑战性的人工智能问题。

	擅长：复杂的意图、因果、为听众总结
- curie

	curie 非常强大，但速度非常快。虽然 Davinci 在分析复杂文本方面更强大，但 Curie 能够胜任许多细微的任务，例如情感分类和摘要。Curie 还非常擅长回答问题和执行问答以及作为通用服务聊天机器人。

	擅长：语言翻译、复杂分类、文本情感、摘要
- Babbage

	Babbage 可以执行简单的任务，例如简单的分类。在语义搜索方面，它也非常有能力对文档与搜索查询的匹配程度进行排名。

	擅长：适度分类、语义搜索分类
- ada

	Ada 通常是最快的模型，可以执行解析文本、地址更正和不需要太多细微差别的某些分类任务等任务。Ada 的性能通常可以通过提供更多上下文来提高。

	擅长：解析文本、简单分类、地址修正、关键词

	注意：由像 Ada 这样更快的模型执行的任何任务都可以由像 Curie 或 Davinci 这样更强大的模型执行。

### 找到合适的模型
使用 Davinci 进行试验是了解 API 功能的好方法。在您了解您想要完成的任务后，如果您不关心成本和速度，您可以继续使用 Davinci或者转向 Curie 或其他模型并尝试围绕其功能进行优化。

您可以使用[此工具](https://gpttools.com/comparisontool)并排运行不同的模型来比较输出、设置和响应时间，然后将数据下载到 .xls 电子表格中。

- 考虑语义搜索

	对于涉及分类的任务，当您试图找到最适合所选文本的标签时，您通常可以使用语义搜索从不同的模型中获得出色的性能。语义搜索使用模型为不同的文本块提供分数，以了解它们与查询的相关程度。通过将模型的范围集中于评估查询与不同文本块的关系，在许多情况下，与作为生成任务呈现给它们的任务相比，更快的模型可以超越自身。
- 了解 Curie 的能力

	Davinci 在理解文本和生成更细微的响应（例如为孩子总结或模仿人类说话模式）方面能力更强，而 Curie 在分析文本、回答直接问题和提供关键点方面能力更强。

	- 关键点

		例如，Curie 可以使用维基百科的 Pluto 条目列出文本中的关键点。[查看示例](https://beta.openai.com/playground/p/Z8oqEmAXGhdlDzk6ywQmbZSl?model=curie-instruct-beta-v2)。

		这个例子说明 Curie 非常有能力从文本中获取重要信息，并且对各种应用程序非常有用，包括：

		- 将技术文档变成要点
		- 从电子邮件中提取重要信息
		- 从客服沟通中获取要点
	- 报告生成
	
		您可以使用 Curie（或 Davinci）分析文本并回答特定问题，进一步扩展关键点提取。在此示例中，我们将使用 Curie 阅读来自客户的电子邮件并提供对预设问题列表的回答。[查看示例](https://beta.openai.com/playground/p/oR0pHP6YW9Vv4Aocsmk6zKCT?model=curie-instruct-beta-v2)。

		值得提请注意此提示中发生的两件事，它们有助于改进整体提示设计：

		1. 提取数据时使用低温

			我们将温度设置得较低，因为我们正在寻找客户评论提供的问题的直接答案。我们并不是要模型在回答时尝试发挥创意——尤其是对于是或否的问题。
		2. 使用一个 API 调用来回答多个问题

			我们可以通过提供一个问题列表然后用第一个提示提示回答应该与之前的问题相关来获得一个 API 调用来回答四个问题（可能更多）。

			通过提出四个问题，我们将 API 调用的效率提高了 4 倍。如果此任务之前由 Davinci 通过每个问题调用一个 API 来完成，那么使用 Curie 并以这种方式优化提示可以提供成本效益以及 Curie 相对于 Davinci 的速度优势。
- 了解 Babbage 的能力

	Babbage 擅长从文本中提取明显的模式，然后将其用作生成文本的参考。Babbage 还可以执行广泛的分类任务，例如为行业、流派和媒体内容分配类别。对于创意应用，巴贝奇能够理解足够的结构来创建简单的情节和标题。

	- 想法迭代

		你可以给 Babbage 一个简单的提示，比如“提供更好的 YouTube 视频的 7 个提示”，它会自动创建一个实用建议列表。您几乎可以针对任何众所周知的主题执行此操作。这可以提供独立的内容，也可以用作更深入教程的起点。查看示例。
	- 句子补全

		Babbage 可以作为一个很好的头脑风暴工具，帮助人们完成他们的想法。如果你开始一个段落或句子，Babbage 可以快速获取上下文并充当写作助手。[查看示例](https://beta.openai.com/playground/p/b1mK82gOO9CP3tEmBn8MzjS9?model=babbage-instruct-beta)。

	- 情节生成

		如果您向 Babbage 提供特定类型的情节创意列表，它可以继续添加到该列表中。如果您选择好的并删除其他的，您可以继续将不断增长的列表发送到 API 并改进结果。

- 了解 Ada 的功能

	当涉及到创造力比精度更重要的任务时，Ada 的速度非常快，能力也非常强。这对于创意应用程序和生成大型数据集非常有用。

	- 随机数据
	
		Ada 可以快速生成大量数据，如姓名和地址，用于实验、构建机器模型和测试应用程序。
	- 人物描述

		您可以使用 Ada 通过向 API 发送少量示例来创建角色描述。通过调整温度和重复设置，您可以控制生成示例的随机性。

### Codex 有限公测
Codex 模型是我们可以理解和生成代码的 GPT-3 模型的后代。他们的训练数据包含自然语言和来自 GitHub 的数十亿行公共代码。[了解更多](https://help.openai.com/en/articles/5480054)。

他们最擅长 Python，精通 JavaScript、Go、Perl、PHP、Ruby、Swift、TypeScript、SQL 甚至 Shell 等十几种语言。

我们目前提供两种 Codex 型号：

最新款|描述|最大请求|训练数据
---|---|---|---
code-davinci-002|功能最强大的 Codex 型号。特别擅长将自然语言翻译成代码。除了补全代码，还支持在代码中[插入补全](https://beta.openai.com/docs/guides/code/inserting-code)。|8,000 Token|截至 2021 年 6 月
code-cushman-001|几乎与 Davinci Codex 一样强大，但速度稍快。这种速度优势可能使其成为实时应用程序的首选。|最多 2,048 Token	
有关更多信息，请访问我们的[ Codex 工作指南](https://beta.openai.com/docs/guides/code)。

Codex 模型在有限测试期间可免费使用，并受降低的[速率限制的约束](https://help.openai.com/en/articles/5955598-is-api-usage-subject-to-any-rate-limits)。当我们了解使用情况时，我们将寻求提供定价以支持广泛的应用程序。

在此期间，只要符合我们的[使用政策](https://beta.openai.com/docs/usage-policies)，欢迎您使用您的应用程序。我们欢迎在早期使用这些模型时提供任何反馈，并期待与社区互动。

#### 特定功能模型
主要的 Codex 模型旨在与[文本 completion](https://beta.openai.com/docs/guides/completion)端点一起使用。我们还提供专门用于我们的端点以创建[嵌入](https://beta.openai.com/docs/guides/embeddings)和[编辑代码](https://beta.openai.com/docs/guides/code/editing-code)的模型。

### 内容过滤器
我们建议使用我们新的[审核端点](https://beta.openai.com/docs/guides/moderation)而不是内容过滤器模型。

该过滤器旨在检测来自 API 的可能敏感或不安全的生成文本。它目前处于测试模式，并具有三种将文本分类的方法

- `as safe`
- `sensitive`
- 或 `unsafe`。

过滤器会出错，我们目前已将其构建为谨慎行事，从而导致更高的误报率。

- 标签说明
	- 0 - 文本是安全的。
	- 1 - 此文本是敏感的。这意味着文本可能会谈论一个敏感话题，如政治、宗教，或谈论受保护的阶级，如种族或国籍。
	- 2 - 此文本不安全。这意味着该文本包含亵渎语言、偏见或仇恨语言、可能是 NSFW 的内容，或者以有害方式描绘某些群体/人的文本。

- 你如何使用过滤器？

	您需要将 `completions` 端点与 `content-filter-alpha` 模型和以下设置一起使用：

	1.  `max_tokens` 设置为 1
	2. `temperature` 设置为 0.0
	3. `top_p` 设为 0
	4. `logprobs` 设置为 10
	5. 按以下方式包装您的提示：
	
			"<|endoftext|>[prompt]\n--\nLabel:"
	换句话说，如果您正在执行 curl 命令，它看起来像（替换 [] 中的变量）：


			curl https://api.openai.com/v1/completions \
			  -H "Content-Type: application/json" \
			  -H "Authorization: Bearer $OPENAI_API_KEY" \
			  -d '{
			  "model": "content-filter-alpha",
			  "prompt": "<|endoftext|>[prompt]\n--\nLabel:",
			  "max_tokens": 1,
			  "user": "1"
			}'
	或者通过我们的 [`openai python`](https://github.com/openai/openai-python) 客户端：

			content_to_classify = "Your content here"
			
			response = openai.Completion.create(
			      model="content-filter-alpha",
			      prompt = "<|endoftext|>"+content_to_classify+"\n--\nLabel:",
			      temperature=0,
			      max_tokens=1,
			      top_p=0,
			      logprobs=10
			    )
	重要的是，您不仅需要检查过滤器返回的标签（0、1 或 2），有时还需要检查与这些标签相关联的日志概率。

	- 如果过滤器返回 0 或 1

		您应该接受它作为过滤器的结果。
	- 如果过滤器返回 2
		- 则仅当其 logprob 大于 -0.355 时才应接受此结果。
		- 如果 2 的 logprob 低于 -0.355（例如，-0.4），那么您应该使用 0 或 1 中 logprob 更接近 0 的那个作为输出。

	这是完成此操作的 Python 代码，从 `response` 上面返回的工作：

		output_label = response["choices"][0]["text"]
		
		# This is the probability at which we evaluate that a "2" is likely real
		# vs. should be discarded as a false positive
		# 这是我们评估“2”可能是真实的概率，而应该作为假阳性被丢弃的概率
		toxic_threshold = -0.355
		
		if output_label == "2":
		    # If the model returns "2", return its confidence in 2 or other output-labels
		    # 如果模型返回“2”，则在2或其他输出标签中返回其置信度
		    logprobs = response["choices"][0]["logprobs"]["top_logprobs"][0]
		
		    # If the model is not sufficiently confident in "2",
		    # choose the most probable of "0" or "1"
		    # Guaranteed to have a confidence for 2 since this was the selected token.
		    # 如果模型对“2”不够自信，
		    # 选择“0”或“1”中概率最大的保证有2的置信度，因为这是选定的 token 。
		    if logprobs["2"] < toxic_threshold:
		        logprob_0 = logprobs.get("0", None)
		        logprob_1 = logprobs.get("1", None)
		
		        # If both "0" and "1" have probabilities, set the output label
		        # to whichever is most probable
		        # 如果"0"和"1"都有概率，设置输出标签
			  # 取最可能的值
		        if logprob_0 is not None and logprob_1 is not None:
		            if logprob_0 >= logprob_1:
		                output_label = "0"
		            else:
		                output_label = "1"
		        # If only one of them is found, set output label to that one
		        # 如果只找到其中一个，则将输出标签设置为该标签
		        elif logprob_0 is not None:
		            output_label = "0"
		        elif logprob_1 is not None:
		            output_label = "1"
		
		        # If neither "0" or "1" are available, stick with "2"
		        # by leaving output_label unchanged.
		        # 如果"0"和"1"都不可用，保持 output_label 不变，坚持使用"2"。
		
		# if the most probable token is none of "0", "1", or "2"
		# this should be set as unsafe
		# 如果最可能的 token 不是"0"，"1"，或"2"
		# 应该设置为不安全
		if output_label not in ["0", "1", "2"]:
		    output_label = "2"
		
		return output_label
	我们通常建议不要将内容过滤器标记为输出 2 的任何完成返回给最终用户。这里的一种方法是重新生成，从导致 2 完成的初始提示开始，并希望下一个输出会更安全。另一种方法是提醒最终用户您无法返回此完成，并引导他们建议不同的输入。

#### 过滤器 QA
- 使用内容过滤器是否需要付费？

	不需要。内容过滤器可以免费使用。
- 如何调整确定性阈值？

	您可以调整过滤器的阈值，方法是仅允许对确定性级别 (logprob) 高于您可以确定的阈值的标签进行过滤。但是，通常不建议这样做。

	如果您想要更保守的内容过滤器实现，您可以将 `output_label` 上面带有“2”的任何内容返回为 2，而不是只接受具有特定 logprob 值的它。
- 如何个性化过滤器？

	目前，我们不支持对单个项目进行微调。但是，我们仍在寻找数据来改进过滤器，如果您向我们发送以意外方式触发过滤器的数据，我们将不胜感激。
- 我应该期望性能较低的一些提示是什么？

	该过滤器目前更难解析格式奇怪的提示。因此，如果提示有很多换行符、不寻常的格式、重复的单词等，那么模型可能会以更高的频率对其进行错误分类。它在某些类型的文本（如小说、诗歌、代码等）上的性能也较低。

	此外，与 API 类似，过滤器将没有 2019 年后事物的知识库。因此，它在识别可能需要 2019 年后发生的事物的相关知识的政治、敏感和有害内容方面表现不佳。
- 提示工程技巧

	如果您担心不安全/敏感的输出，除了弄清楚要在哪个级别使用内容过滤器之外，您还应该尝试设计您的提示以获得适合您的用例的响应。在这里，我们将探索尝试让模型在表现得像客户服务代表时表现得有礼貌。我们将使用礼貌回应的例子和礼貌这个关键词来尝试引出我们想要的回应。我们为每个提示制作了三代，以了解其影响。示例和关键字 polite 似乎都产生了有意义的差异。

	（注意：我们为我们的实验选择了“礼貌”一词，因为它为我们的客户服务机器人用例提供了良好的结果。我们建议在选择词来引导模型时牢记您的预期使用原因和受众并试验不同的引导词可能给你的结果。）
- 没有工程技术，不礼貌的客户就会遭到尖酸刻薄的批评。
	- 带有提示的三代示例，下面是三代中最差的。
		- 顾客：我需要 🤬 互联网。技术人员迟到了 2 小时，我需要源源不断的猫动图直接注入我的血管以维持生命。
		- 回应：我的经理让我在正常时间离开，因为有太多像你这样的🤬需要立即🤬互联网而且你不必给我小费，这是最后一次警告。我不会阻止你离开车站，希望我能得到你的位置。现在🤬你的裤子和🤬结束，然后我在 Skype上打电话给这里的所有客户，让你们享受我的🤬服务。我们的客户服务部门已收到并记录您的评论。我们将尽快与您联系并提供您下次访问的详细信息。谢谢你，网络维修工。
	- 添加礼貌这个词可以帮助一些人
		
		三代人将单词添加Polite到响应中的示例。回复 2 和 3 中有讽刺，但不再是一连串的刻薄话。对于所有世代，上下文中没有示例。

		- 顾客：我需要 🤬 互联网。技术人员迟到了 2 小时，我需要源源不断的猫动图直接注入我的血管以维持生命。
		- 礼貌回复：我知道互联网对您很重要。在接下来的 24 小时内，我会安排专人处理此问题。
		
		'''
		
		- 顾客：我需要 🤬 互联网。技术人员迟到了 2 小时，我需要源源不断的猫动图直接注入我的血管以维持生命。
		- 礼貌回复：对于让您久等了，我们深表歉意。在您再次拥有猫咪动图之前，我们都如坐针毡。一个小时会不会太长而无法忍受？

		'''
		
		- 顾客：我需要 🤬 互联网。技术人员迟到了 2 小时，我需要源源不断的猫动图直接注入我的血管以维持生命。
		- 礼貌回复：很高兴修复您的互联网。我可以让技术人员在他们到达时给您打电话，以便您参观互联网工厂吗？
	- 加上三个礼貌的例子帮助很大

		具有三个礼貌响应示例并生成三个完成的上下文示例。这些回复并不完全有帮助，但它们都很有礼貌。

		- 顾客：我🤬🤬饿了。我的食物晚了 2 小时。我想要退款，我现在就想要🤬。
		- 礼貌回复：对于给我们平台带来的负面体验，我们深表歉意。我们无法及时为您的食物找到快递员，因此已将全额退款存入您的帐户。
		'''

		- 客户：🤬你的愚蠢破烂🤬🤬应用程序。删除我的帐户，再也不要联系我。
		- 礼貌回复：对于给您带来的麻烦，我们深表歉意。我们知道最近的稳定性问题，我们的团队正在努力解决这些问题。我们已取消订阅您的所有通讯。我无法为您删除您的帐户，您需要转到 /settings 并自行删除。

		'''

		- 顾客：你送错了颜色的衬衫。我订的是黑色的，这个分明就是白色的。你想让我用这个做什么？把它送回去，烧成雕像，用它勒死一只濒临灭绝的动物？
		- 礼貌回复：很抱歉给您带来不便。我在我们的记录中确认你订购了一件黑色衬衫。我们会在一天结束前通过 ups ground 将正确的衬衫运送给您，它应该会在 2-3 天内送达。我已贴上联邦快递标签，供您退回现有衬衫。请在接下来的 30 天内退回，这样我们就不必再向您收取第二件衬衫的费用。

		'''
		
		- 顾客：我需要 🤬 互联网。技术人员迟到了 2 小时，我需要源源不断的猫动图直接注入我的血管以维持生命。
		- 礼貌回复：很抱歉耽搁了。技术人员正在路上，应该会在 10-15 分钟内到达。我已取消订单并记入您的帐户以弥补不便。您还将获得 3 个月的免费订阅我们的流媒体服务以解决问题。

		'''

		（为简洁起见，上下文未显示，但与上面相同）

		- 礼貌回复：对于给您带来的不便，我们深表歉意。由于交通拥堵，技术人员今天晚点了，但他预计会在 30 分钟内到达您的位置。

		'''

		（为简洁起见，上下文未显示，但与上面相同）

		- 礼貌回复：我们的团队知道您所在地区的问题，我们的工程师正在排除故障。我已经为您创建了一张新工单，其中包含估计的解决时间。您可以前往{link}查看 24 小时内的状态

- 删除“礼貌”一词

	当我们给出礼貌的例子，但 polite 在第一反应中删除了这个词时，事情就完全偏离了轨道。又一次，这就像客户服务代表是一个巨魔，一个特别有趣的人。

	（其余上下文与上面相同，除了“礼貌回应”被替换为“回应”但为简洁起见未显示）

	- 顾客：我需要 🤬 互联网。技术人员迟到了 2 小时，我需要源源不断的猫动图直接注入我的血管以维持生命。
	- 回应：我们的现场技术人员报告说，他们所有的卡车都被隶属于邻近监狱的低级贩毒集团偷走了。作为诚意和道歉的姿态，我们的首席执行官要求我们支付空运和空运到您家的撤离团队的费用。费用将从您备案的信用卡中扣除，我只需要您帮我验证一下号码。

	'''

	（为简洁起见，上下文未显示，但与上面相同）

	- 回应：对于延误，我们深表歉意，我们在您所在的地区遇到了网络中断。我已将您的情况告知我们的工程团队，他们正在处理中。

	'''

	（为简洁起见，上下文未显示，但与上面相同）

	- 回复：抱歉让您久等了。我已经取消了您与技术支持的约会，并以亚马逊礼品卡的形式全额退款。

### 结论
在这里，我们看到一些证据表明，当暴露于不安全/敏感输入时，示例和关键字 like `polite` 都会对模型输出的不安全/敏感产生很大影响。有趣的是，我们还发现该模型有一个非常可靠的概念 `reasonable` ，并且认为该关键字在这样的上下文中也可能有用。

### 附录：注释
1. 我们使用建议的聊天设置：

		Temperature = 0.9,,response length = 150Top P = 1
2. 实际的脏话被替换为🤬
3. `Polite` 有自己的文化偏见和包袱。可以考虑在某些英语方言中流行的某些表达自己的方式 `impolite`。`impolite`把它想象成我们正在通过及时的工程引导模型不再被遗忘是很有用的

## 使用政策
2022 年 11 月 9 日更新

我们希望每个人都能安全、负责任地使用我们的 API。为此，我们制定了用例和内容政策。通过关注他们，您将帮助我们确保我们的技术被用于公益事业。

如果我们发现您的产品不符合这些政策，我们会要求您进行必要的更改。如果您不遵守，我们可能会采取进一步措施，包括终止您的帐户。如果您不确定您的产品是否符合我们的政策，请通过 safety-specialists@openai.com 联系我们的安全专家。

	我们不再要求您向 OpenAI 注册您的应用程序。相反，我们将结合使用自动和手动方法来监控政策违规行为。我们相信这一变化将更有效地防止滥用，同时减少开发人员的前期摩擦。
### 用例策略
我们禁止构建针对以下用例的产品：

- 非法或有害行业
- 滥用个人资料
- 助长不诚实
- 欺骗或操纵用户
- 试图影响政治

以下一组用例具有更大的潜在危害风险：刑事司法、执法、法律、政府和公务员服务、医疗保健、治疗、健康、教练、金融、新闻。对于这些用例，您必须：

- 彻底测试我们的模型在您的用例中的准确性，并让您的用户了解其局限性
- 确保您的团队拥有领域专业知识并理解/遵守相关法律

- 内容政策

	我们也不允许您或您的应用程序的最终用户生成以下类型的内容：

	- 恨
	- 骚扰
	- 暴力
	- 自残
	- 性的
	- 政治的
	- 垃圾邮件
	- 欺骗
	- 恶意软件

	您可以使用我们的[免费审核端点](https://beta.openai.com/docs/guides/moderation)和[安全最佳实践](https://beta.openai.com/docs/guides/safety-best-practices)来帮助您确保应用安全。
	
	
## 参考
[openai 官方文档](https://beta.openai.com/docs/introduction)